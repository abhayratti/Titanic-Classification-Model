{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORSzoF9ODoUOFS+UuvEtA7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhayratti/Titanic-Classification-Model/blob/main/Titanic_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOSFPSnlQnRu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/train.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q5s0GoWNQry4",
        "outputId": "0ab9bae2-e40f-4411-9717-85e10d6e0ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e72e8e6-fde9-406b-a85c-b8e91a742c4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e72e8e6-fde9-406b-a85c-b8e91a742c4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e72e8e6-fde9-406b-a85c-b8e91a742c4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e72e8e6-fde9-406b-a85c-b8e91a742c4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
        "data = data.dropna()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "28KBUKnnRP_1",
        "outputId": "144f452c-1f9f-4eb1-e80a-4cb3b0894379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived  Pclass     Sex   Age     Fare\n",
              "0         0       3    male  22.0   7.2500\n",
              "1         1       1  female  38.0  71.2833\n",
              "2         1       3  female  26.0   7.9250\n",
              "3         1       1  female  35.0  53.1000\n",
              "4         0       3    male  35.0   8.0500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceb56833-d58a-4cb6-a448-b98da39e2784\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceb56833-d58a-4cb6-a448-b98da39e2784')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ceb56833-d58a-4cb6-a448-b98da39e2784 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ceb56833-d58a-4cb6-a448-b98da39e2784');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "1ZP6rE75SN1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "data['Sex'] = le.fit_transform(data['Sex'])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Awhv1JoGSTSS",
        "outputId": "ea641e25-02c4-4d83-915e-1ecee7fa20e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived  Pclass  Sex   Age     Fare\n",
              "0         0       3    1  22.0   7.2500\n",
              "1         1       1    0  38.0  71.2833\n",
              "2         1       3    0  26.0   7.9250\n",
              "3         1       1    0  35.0  53.1000\n",
              "4         0       3    1  35.0   8.0500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56ff950a-1821-4c20-bf51-cd6788a51c4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56ff950a-1821-4c20-bf51-cd6788a51c4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56ff950a-1821-4c20-bf51-cd6788a51c4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56ff950a-1821-4c20-bf51-cd6788a51c4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Pclass', 'Sex', 'Age', 'Fare']\n",
        "data_features = data[features]\n",
        "\n",
        "data_features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YkEYMCQ9S2n0",
        "outputId": "e38951ff-d64f-4076-c5c6-c2fcb00f013a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pclass  Sex   Age     Fare\n",
              "0       3    1  22.0   7.2500\n",
              "1       1    0  38.0  71.2833\n",
              "2       3    0  26.0   7.9250\n",
              "3       1    0  35.0  53.1000\n",
              "4       3    1  35.0   8.0500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c07a2cf7-6083-43c1-948e-51108b36ea92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c07a2cf7-6083-43c1-948e-51108b36ea92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c07a2cf7-6083-43c1-948e-51108b36ea92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c07a2cf7-6083-43c1-948e-51108b36ea92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_features = pd.get_dummies(data_features, columns=['Pclass'])\n",
        "\n",
        "data_features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i8s8KFL_TJhF",
        "outputId": "e44aae74-b6f3-4b87-da5c-fd68888ea772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sex   Age     Fare  Pclass_1  Pclass_2  Pclass_3\n",
              "0    1  22.0   7.2500         0         0         1\n",
              "1    0  38.0  71.2833         1         0         0\n",
              "2    0  26.0   7.9250         0         0         1\n",
              "3    0  35.0  53.1000         1         0         0\n",
              "4    1  35.0   8.0500         0         0         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7de258aa-07ec-4a3a-937a-1391ba0595cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7de258aa-07ec-4a3a-937a-1391ba0595cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7de258aa-07ec-4a3a-937a-1391ba0595cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7de258aa-07ec-4a3a-937a-1391ba0595cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_target = data[['Survived']]\n",
        "\n",
        "data_target.head() # 0 - dead | 1 - survived"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "E5fLbZ3UTRop",
        "outputId": "0c1de841-92f5-4169-cc30-c0c166b44a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived\n",
              "0         0\n",
              "1         1\n",
              "2         1\n",
              "3         1\n",
              "4         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79995bf5-44bc-48e8-a875-df916f911aad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79995bf5-44bc-48e8-a875-df916f911aad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79995bf5-44bc-48e8-a875-df916f911aad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79995bf5-44bc-48e8-a875-df916f911aad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "k-rOCzvTUQx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, x_test, Y_train, y_test = train_test_split(data_features,\n",
        "                                                    data_target,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=0)"
      ],
      "metadata": {
        "id": "n3dHgeQ6UfaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qlXeqyfWEee",
        "outputId": "680067b0-01e9-4947-da38-e226a54130d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((571, 6), (571, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2UA0wNImWJA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_ = torch.from_numpy(X_train.values).float()\n",
        "Xtest_ = torch.from_numpy(x_test.values).float()"
      ],
      "metadata": {
        "id": "CnK5hjtMWM5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_.shape, Xtest_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zNDmlAlWa2H",
        "outputId": "b9d010b9-e048-48a6-c980-c93b8f61a463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([571, 6]), torch.Size([143, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape data to match y-label format for our loss function (NLL)\n",
        "Ytrain_ = torch.from_numpy(Y_train.values).view(1,-1)[0] # \".view(1,-1)[0] extracts y-labels as a 1D tensor\"\n",
        "Ytest_ = torch.from_numpy(y_test.values).view(1,-1)[0]"
      ],
      "metadata": {
        "id": "eaEuq98NWgt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain_.shape, Ytest_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j_vv4BGW8Qv",
        "outputId": "dd53656d-dfb6-4aa2-ed75-50bc7c211296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([571]), torch.Size([143]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "_lEt24WkXBib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 6\n",
        "output_size = 2 # survived or not\n",
        "hidden_one_size = 20\n",
        "hidden_two_size = 10"
      ],
      "metadata": {
        "id": "i9Uu-XKAXbtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# structure of NN\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_one_size)\n",
        "    self.fc2 = nn.Linear(hidden_one_size, hidden_two_size)\n",
        "    self.fc3 = nn.Linear(hidden_two_size, output_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.sigmoid(self.fc1(x))\n",
        "    x = F.sigmoid(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "aVtjTYPyYBzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start a model of this NN\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "0sS8jSl0ZNcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "TTaugWyuZXQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "epoch_data = []\n",
        "epochs = 1001"
      ],
      "metadata": {
        "id": "ltBPoaRLZ7V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (1, 2):\n",
        "  optimizer.zero_grad()\n",
        "  Ypred = model(Xtrain_)\n",
        "\n",
        "  print(Ypred.shape, Ytrain_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQrB6ikQhUFA",
        "outputId": "1a28410a-fb36-44a9-b9fa-5d6c0f2a072e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([571, 2]) torch.Size([571])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs):\n",
        "  # forward pass\n",
        "  optimizer.zero_grad() # refreshing the grads for every forward pass\n",
        "  Ypred = model(Xtrain_)\n",
        "\n",
        "  # backward pass\n",
        "  loss = loss_fn(Ypred, Ytrain_) # calculate loss\n",
        "  loss.backward() # calculate gradients\n",
        "\n",
        "  optimizer.step() # update params\n",
        "\n",
        "  # testing data\n",
        "  Ypred_test = model(Xtest_)\n",
        "  loss_test = loss_fn(Ypred_test, Ytest_)\n",
        "\n",
        "  _, pred = Ypred_test.data.max(1)\n",
        "\n",
        "  # accuracy\n",
        "  p1 = pred.eq(Ytest_.data).sum().item()\n",
        "  p2 = y_test.values.size\n",
        "  print(p1, p2, 'Accuracy: ', p1 / p2)\n",
        "\n",
        "  # accuracy = pred.eq(Ytest_.data).sum().item() / y_test.values.size\n",
        "  # epoch_data.append([epoch, loss.data.item(), loss_test.data.item(), accuracy])\n",
        "\n",
        "  # if epoch % 100 == 0:\n",
        "  #   print ('epoch - %d (%d%%) train loss - %.2f test loss - %.2f accuracy - %.4f' \\\n",
        "  #          % (epoch, epoch/150 * 10 , loss.data.item(), loss_test.data.item(), accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp5GwU-UZ_tP",
        "outputId": "83eab9dc-60e3-44cc-b831-3fe9d3a2d8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 143 Accuracy:  0.44755244755244755\n",
            "59 143 Accuracy:  0.4125874125874126\n",
            "74 143 Accuracy:  0.5174825174825175\n",
            "89 143 Accuracy:  0.6223776223776224\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "79 143 Accuracy:  0.5524475524475524\n",
            "82 143 Accuracy:  0.5734265734265734\n",
            "81 143 Accuracy:  0.5664335664335665\n",
            "80 143 Accuracy:  0.5594405594405595\n",
            "80 143 Accuracy:  0.5594405594405595\n",
            "80 143 Accuracy:  0.5594405594405595\n",
            "80 143 Accuracy:  0.5594405594405595\n",
            "80 143 Accuracy:  0.5594405594405595\n",
            "81 143 Accuracy:  0.5664335664335665\n",
            "85 143 Accuracy:  0.5944055944055944\n",
            "90 143 Accuracy:  0.6293706293706294\n",
            "91 143 Accuracy:  0.6363636363636364\n",
            "93 143 Accuracy:  0.6503496503496503\n",
            "94 143 Accuracy:  0.6573426573426573\n",
            "95 143 Accuracy:  0.6643356643356644\n",
            "95 143 Accuracy:  0.6643356643356644\n",
            "96 143 Accuracy:  0.6713286713286714\n",
            "96 143 Accuracy:  0.6713286713286714\n",
            "96 143 Accuracy:  0.6713286713286714\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "97 143 Accuracy:  0.6783216783216783\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "98 143 Accuracy:  0.6853146853146853\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "99 143 Accuracy:  0.6923076923076923\n",
            "100 143 Accuracy:  0.6993006993006993\n",
            "100 143 Accuracy:  0.6993006993006993\n",
            "101 143 Accuracy:  0.7062937062937062\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "102 143 Accuracy:  0.7132867132867133\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "103 143 Accuracy:  0.7202797202797203\n",
            "104 143 Accuracy:  0.7272727272727273\n",
            "104 143 Accuracy:  0.7272727272727273\n",
            "104 143 Accuracy:  0.7272727272727273\n",
            "104 143 Accuracy:  0.7272727272727273\n",
            "104 143 Accuracy:  0.7272727272727273\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "105 143 Accuracy:  0.7342657342657343\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "106 143 Accuracy:  0.7412587412587412\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "107 143 Accuracy:  0.7482517482517482\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "108 143 Accuracy:  0.7552447552447552\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "110 143 Accuracy:  0.7692307692307693\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "109 143 Accuracy:  0.7622377622377622\n",
            "110 143 Accuracy:  0.7692307692307693\n",
            "110 143 Accuracy:  0.7692307692307693\n",
            "110 143 Accuracy:  0.7692307692307693\n",
            "111 143 Accuracy:  0.7762237762237763\n",
            "110 143 Accuracy:  0.7692307692307693\n",
            "110 143 Accuracy:  0.7692307692307693\n",
            "111 143 Accuracy:  0.7762237762237763\n",
            "111 143 Accuracy:  0.7762237762237763\n",
            "111 143 Accuracy:  0.7762237762237763\n",
            "111 143 Accuracy:  0.7762237762237763\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "112 143 Accuracy:  0.7832167832167832\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "113 143 Accuracy:  0.7902097902097902\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "113 143 Accuracy:  0.7902097902097902\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "115 143 Accuracy:  0.8041958041958042\n",
            "114 143 Accuracy:  0.7972027972027972\n",
            "115 143 Accuracy:  0.8041958041958042\n",
            "116 143 Accuracy:  0.8111888111888111\n",
            "116 143 Accuracy:  0.8111888111888111\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "122 143 Accuracy:  0.8531468531468531\n",
            "121 143 Accuracy:  0.8461538461538461\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "120 143 Accuracy:  0.8391608391608392\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "117 143 Accuracy:  0.8181818181818182\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "119 143 Accuracy:  0.8321678321678322\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n",
            "118 143 Accuracy:  0.8251748251748252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_epochs_data = pd.DataFrame(epoch_data, columns=['epoch', 'train_loss', 'test_loss', 'accuracy'])"
      ],
      "metadata": {
        "id": "6khp-W3-aJ5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zgrGRLo0twtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "df_epochs_data[['train_loss', 'test_loss']].plot(ax=ax1)\n",
        "df_epochs_data[['accuracy']].plot(ax=ax2)\n",
        "plt.ylim(ymin=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "XkfgMPi7tyyy",
        "outputId": "2e81c5b1-6eba-4cda-f4e1-7c60acbdf105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5a100ec203b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_epochs_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_epochs_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# no non-numeric frames or series allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no numeric data to plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}